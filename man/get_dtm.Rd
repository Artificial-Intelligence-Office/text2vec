% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/matrix.R
\name{get_dtm}
\alias{get_dtm}
\title{Creates Document-Term matrix construction}
\usage{
get_dtm(corpus, dictionary = NULL, stopwords = NULL, type = c("dgCMatrix",
  "dgTMatrix", "LDA_C", "LIL"))
}
\arguments{
\item{corpus}{HashCorpus or DictCorpus object. See \link{create_vocab_corpus} for details.}

\item{dictionary}{\link{character} or \link{NULL} -  use only words from this dict
dictionary in Document-Term-Matrix construction.
NULL if all words should be used.}

\item{stopwords}{\link{character} or \link{NULL} - words to remove from DTM}

\item{type}{character, one of \code{c("dgCMatrix", "dgTMatrix", "LDA_C", "LIL")}.
"LDA_C" - Blei's lda-c format (list of 2*doc_terms_size),
see \url{https://www.cs.princeton.edu/~blei/lda-c/readme.txt}
"LIL" - same as LDA-C, but without terms count. Useful for Minhash algorithm.}
}
\description{
Creates Document-Term matrix from Corpus object.
}
\examples{
\dontrun{
preprocess_fun <- function(txt) {
   txt \%>\%
     tolower
}
txt <- c(paste(letters[c(4:7, 5:12)], collapse = " "),
 paste(LETTERS[c(5:9, 7:12) ], collapse = " "))
corpus <- create_vocab_corpus(txt,
   preprocess_fun = preprocess_fun,
   #split text by word boundaries
   tokenizer = regexp_tokenizer,
   # by small pieces - call underlying C++ code for each document
   batch_size = 1
   )
# or if stemming is needed
stemfun <- function(txt_char_vec, lang = 'en')
 lapply(txt_char_vec, function(x) SnowballC::wordStem(x, language = lang))
preprocess_fun <- function(txt) {
   txt \%>\%
     tolower \%>\%
     #split text by word boundaries
     regexp_tokenizer \%>\%
     # stem with Porter stemmer
     lapply(SnowballC::wordStem, language = 'en')
}
dtm <- get_dtm(corpus, dictionary = letters[4:8], stopwords = letters[5:6] )
}
}

