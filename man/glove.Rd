% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/glove.R
\name{glove}
\alias{glove}
\alias{glove.Matrix}
\title{Perform fit of the GloVe model.}
\usage{
glove(tcm, shuffle = TRUE, ...)

\method{glove}{Matrix}(tcm, shuffle = TRUE, word_vectors_size, x_max,
  num_iters, learning_rate = 0.05, verbose = TRUE,
  convergence_threshold = 0, grain_size = 100000L, ...)
}
\arguments{
\item{tcm}{object which represents Term-Coocurence matrix, which used in training.
At the moment only \code{dgTMatrix} or (coercible to \code{dgTMatrix}) is supported.
In future releases we will add support for out-of-core learning and streaming TCM from disk.}

\item{shuffle}{\code{logical} whether to perform shuffling before each iteration.}

\item{...}{arguments passed to other methods (not used at the moment).
Generelly good idea for stochastic gradient descent}

\item{word_vectors_size}{desired dimenson for word vectors}

\item{x_max}{maximum number of cooccurences to use in weighting function.
See GloVe paper for details: \url{http://nlp.stanford.edu/pubs/glove.pdf}}

\item{num_iters}{number of AdaGrad epochs}

\item{learning_rate}{learning rate for SGD, I don't recommend to modify this parameter,
AdaGrad will quickly adjust it to optimal.}

\item{verbose}{whether to display training inforamtion}

\item{convergence_threshold}{defines early stopping stratergy. We stop fitting when
one of two following conditions will be satisfied:
a)  spent all iterations

or

b) \code{cost_previous_iter} / \code{cost_current_iter} - 1 < convergence_threshold}

\item{grain_size}{I don't recommend to adjust this paramenter. This is the grain_size
for \code{RcppParallel::parallelReduce}.
See \url{http://rcppcore.github.io/RcppParallel/#grain-size} for details.}
}
\description{
Train GloVe word embeddings model via fully asynchronous parallel AdaGrad.
}
\seealso{
\url{http://nlp.stanford.edu/projects/glove/}
}

