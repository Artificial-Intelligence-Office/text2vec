% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/corpus.R
\name{create_vocab_corpus}
\alias{create_hash_corpus}
\alias{create_vocab_corpus}
\title{RAM-friendly streaming corpus construction. Vocabulary or hash based.}
\usage{
create_vocab_corpus(src, vocab, preprocess_fun = identity,
  tokenizer = regexp_tokenizer, ngram = c(min_n = 1L, max_n = 1L),
  batch_size = 10, limit = NULL, progress = T)

create_hash_corpus(src, preprocess_fun = identity,
  tokenizer = regexp_tokenizer, ngram = c(min_n = 1L, max_n = 1L),
  hash_size = 2^18, signed_hash = F, batch_size = 10, limit = NULL,
  progress = T)
}
\arguments{
\item{src}{\code{character} vector or \link{connection} object.}

\item{vocab}{user-defined vocabulary. \code{NULL} in case when we should build corpus from
\code{src}. Or \bold{ordered} \code{character vector} when we want to reconstruct it from train data.
Usually \code{vocab} obtained from previous corpus construction via \code{source_corpus$vocab} call.
See \link{VocabCorpus}.}

\item{preprocess_fun}{\bold{\code{function}} which takes \code{character vector}
and \bold{do all preprocessing} (including stemming if needed). See "Details" section.
usually \code{preprocess_fun} should return \code{character vector}.}

\item{tokenizer}{\bold{\code{function}} which takes \bold{takes \code{character vector}},
split it into tokens and \bold{return \link{list} of \code{character vector}s}.}

\item{ngram}{\code{vector} of \bold{length = 2}. The lower and upper boundary of the range of
n-values for different n-grams to be extracted.
All values of n such that \code{min_n <= n <= max_n} will be used.}

\item{batch_size}{\code{integer} - how many documents we want to convert
into vector representation per one fetching from connection.
Generally setting this to large number speeding up DTM construction,
but more RAM intensive.}

\item{limit}{\code{integer} - maximum number of documents we want to
transform to vector representation.}

\item{progress}{\code{logical} - show progress bar}

\item{hash_size}{\code{integer >= 0 } - number of hash-buckets
for hashing trick (feature hashing). Preferably power of 2 number.}

\item{signed_hash}{\code{boolean} value. Indicating whether to use second hash-function
to reduce impact of collisions.}
}
\value{
corpus object, stored outside of R's heap.(XPtr - external pointer).
We can add documents into this corpus by reference - no copy at all.
See source code for details.
}
\description{
RAM-friendly streaming corpus construction. Vocabulary or hash based.
}
\details{
Usually preprocessing involve following steps:

1) convert text to UTF-8, see \link{iconv}, \link{enc2utf8}

2) Preprocess - convert text to lower case, etc. See \link{tolower},
\code{stringr::str_replace}
\code{preprocess_fun} should return \code{character vector} as output. This output
will used as input to \code{tokenizer} function.
3) tokenize text - see \code{stringr::str_split} for example

Also [very optionally] after this you can add stemming step. For this you should
tokenize text yourself (see \link{regexp_tokenizer}) and then apply some stemming
function to each word. For stemming see \code{SnowballC::wordStem}.
In this case \code{preprocess_fun} will return \code{list} of \code{character} vectors so
there will be nothing to do in \code{tokenizer} function. So you should set \code{tokenizer}
to \link{identity} function.

For full process example see \link{get_dtm}.
}

